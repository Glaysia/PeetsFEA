{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import module\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from pycaret.regression import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.max_seq_items = None\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "from py_module.load_data import load_data\n",
    "from py_module.plot_data import plot_histogram\n",
    "from py_module.regression import *\n",
    "from py_module.pre_processing import *\n",
    "from py_module.verify import *\n",
    "from py_module.etc import *\n",
    "from py_module.compare import *\n",
    "import warnings, logging, sys\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)     # pandas 등\n",
    "logging.getLogger().handlers.clear()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "import logging, sys, warnings, pandas as pd\n",
    "\n",
    "# ① logging 핸들러 리셋\n",
    "logging.getLogger().handlers.clear()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, force=True)\n",
    "\n",
    "# ② pandas SettingWithCopyWarning 무시 (원인 해결 후에도 잔여 경고 차단용)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "    \n",
    "    # column 데이터만 추출, 1/4 분위와 3/4 분위 지점을 np.percentile로 구함. \n",
    "    data = df[column]\n",
    "    quantile_25 = np.percentile(data.values,10)  # 1/4 분위\n",
    "    quantile_75 = np.percentile(data.values,90)  # 3/4 분위\n",
    "    \n",
    "    # IQR을 구하고, IQR에 1.5를 곱하여 최대값과 최소값 지점 구함. \n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr * weight\n",
    "    lowest_val = quantile_25 - iqr_weight  # 이상치 최소 기준\n",
    "    highest_val = quantile_75 + iqr_weight # 이상치 최대 기준\n",
    "    \n",
    "    # 최대값 보다 크거나, 최소값 보다 작은 값을 아웃라이어로 설정하고 DataFrame index 반환. \n",
    "    outlier_index = data[(data < lowest_val) | (data > highest_val)].index\n",
    "    \n",
    "    return outlier_index\n",
    "\n",
    "def outlier_remove(data) :\n",
    "    col_input = list(data.columns)[:-2]\n",
    "    col_input = list(data.columns)\n",
    "\n",
    "    # outlier 탐색 및 제거\n",
    "    outlier_index = {}\n",
    "    for i, colName in enumerate(col_input):\n",
    "        outlier_index[i] = get_outlier(df=data, column=f'{colName}', weight=1.5)\n",
    "    outlier_index\n",
    "\n",
    "    # 각각의 숫자들 리스트 안에 넣기\n",
    "    outlier_list = []\n",
    "    for i in range(len(outlier_index)):\n",
    "        if list(outlier_index[i].values) == []:\n",
    "            continue\n",
    "        outlier_list.append(list(outlier_index[i].values))\n",
    "\n",
    "\n",
    "    # 리스트 안의 리스트들을 하나로 합치기\n",
    "    outlier_list = sum(outlier_list , [])\n",
    "    print('개수:', len(outlier_list))\n",
    "\n",
    "    # 중복 숫자 제거\n",
    "    outlier_list = set(outlier_list)\n",
    "    print('개수:', len(outlier_list))\n",
    "\n",
    "    # 다시 리스트 타입으로 변환\n",
    "    outlier_list = list(outlier_list)\n",
    "    print(type(outlier_list))\n",
    "\n",
    "    # 리스트 숫자 정렬\n",
    "    outlier_list.sort()\n",
    "\n",
    "    # outlier를 갖는 index에 해당하는 data drop\n",
    "    for i in outlier_list:\n",
    "        data.drop(i, axis=0, inplace=True)\n",
    "\n",
    "    print(f'필터링 후 : {data.shape}')\n",
    "\n",
    "    return data\n",
    "\n",
    "def train_model(X,Y) :\n",
    "\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state = 765)\n",
    "\n",
    "    Z = pd.concat([X_train,Y_train],axis=1)\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [1000, 5000, 10000, 20000],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.15],\n",
    "        \"num_leaves\": [3, 7, 11, 15],\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_r2 = float(\"-inf\")\n",
    "    best_params = None\n",
    "\n",
    "    for n_est, lr, n_leaf in product(\n",
    "        param_grid[\"n_estimators\"],\n",
    "        param_grid[\"learning_rate\"],\n",
    "        param_grid[\"num_leaves\"]\n",
    "    ):\n",
    "        model = LGBMRegressor(\n",
    "            random_state=765,\n",
    "            n_estimators=n_est,\n",
    "            learning_rate=lr,\n",
    "            num_leaves=n_leaf,\n",
    "            max_depth=-1,\n",
    "            objective=\"poisson\",\n",
    "            boosting_type=\"gbdt\",\n",
    "        )\n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        r2 = r2_score(Y_test, preds)\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_model = model\n",
    "            best_params = {\n",
    "                \"n_estimators\": n_est,\n",
    "                \"learning_rate\": lr,\n",
    "                \"num_leaves\": n_leaf,\n",
    "            }\n",
    "\n",
    "    print(f\"Best R2: {best_r2:.6f} with params: {best_params}\")    \n",
    "    \n",
    "\n",
    "    return best_model, best_r2\n",
    "\n",
    "def train_model_v2(X,Y) :\n",
    "\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state = 765)\n",
    "\n",
    "    Z = pd.concat([X_train,Y_train],axis=1)\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [1000, 5000, 10000, 20000],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.15],\n",
    "        \"num_leaves\": [3, 7, 11, 15],\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_r2 = float(\"-inf\")\n",
    "    best_params = None\n",
    "\n",
    "    for n_est, lr, n_leaf in product(\n",
    "        param_grid[\"n_estimators\"],\n",
    "        param_grid[\"learning_rate\"],\n",
    "        param_grid[\"num_leaves\"]\n",
    "    ):\n",
    "        model = LGBMRegressor(\n",
    "            random_state=765,\n",
    "            n_estimators=n_est,\n",
    "            learning_rate=lr,\n",
    "            num_leaves=n_leaf,\n",
    "            max_depth=-1,\n",
    "            objective=\"poisson\",\n",
    "            boosting_type=\"gbdt\",\n",
    "        )\n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        r2 = r2_score(Y_test, preds)\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_model = model\n",
    "            best_params = {\n",
    "                \"n_estimators\": n_est,\n",
    "                \"learning_rate\": lr,\n",
    "                \"num_leaves\": n_leaf,\n",
    "            }\n",
    "\n",
    "    print(f\"Best R2: {best_r2:.6f} with params: {best_params}\")    \n",
    "    \n",
    "\n",
    "    return best_model, X_train,X_test,Y_train,Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개수: 2538\n",
      "개수: 635\n",
      "<class 'list'>\n",
      "필터링 후 : (2533, 56)\n",
      "Using 23/23 provided input columns\n"
     ]
    }
   ],
   "source": [
    "column_names =  [\"freq\",\"input_voltage\",\"w1\",\"l1_leg\",\"l1_top\",\"l2\",\"h1\",\"l1_center\",\n",
    "                \"Tx_turns\",\"Tx_width\",\"Tx_height\",\"Tx_space_x\",\"Tx_space_y\",\"Tx_preg\",\n",
    "                \"Rx_width\",\"Rx_height\",\"Rx_space_x\",\"Rx_space_y\",\"Rx_preg\",\"g2\",\n",
    "                \"Tx_layer_space_x\",\"Tx_layer_space_y\",\"Tx_current\",\n",
    "                \"Ltx\",\"Lrx1\",\"Lrx2\",\"M1\",\"M2\",\"k1\",\"k2\",\"Lmt\",\"Lmr1\",\"Lmr2\",\n",
    "                \"Llt\",\"Llr1\",\"Llr2\",\"Rtx\",\"Rrx1\",\"Rrx2\",\n",
    "                \"Rx_current_optimetric\",\"copperloss_Tx\",\"copperloss_Rx1\",\"copperloss_Rx2\",\n",
    "                \"magnetizing_current_optimetric\",\"coreloss\",\"B_core\",\"B_left\",\"B_right\",\"B_center\",\"B_top_left\",\"B_bottom_left\",\"B_top_right\",\"B_bottom_right\",\n",
    "                \"magnetizing_copperloss_Tx\",\"magnetizing_copperloss_Rx1\",\"magnetizing_copperloss_Rx2\"]\n",
    "raw_data =  pd.read_csv(\"output_data.csv\",delimiter=\",\",names=column_names,header=None,skiprows=1)\n",
    "\n",
    "\n",
    "raw_data.head()\n",
    "cols = ['M1', 'M2', 'k1', 'k2']\n",
    "raw_data[cols] = raw_data[cols].apply(pd.to_numeric, errors='coerce').abs()\n",
    "\n",
    "# '(width_ratio)*l2*ratio/({math.ceil(pri_turns/2)})\n",
    "# 2. one-click\n",
    "# Inputs specified by user: treat these as features; others as targets\n",
    "input_cols_copper = [\"freq\",\"w1\",\"l1_leg\",\"l1_top\",\"l2\",\"h1\",\"l1_center\",\n",
    "                \"Tx_turns\",\"Tx_width\",\"Tx_height\",\"Tx_space_x\",\"Tx_space_y\",\"Tx_preg\",\n",
    "                \"Rx_width\",\"Rx_height\",\"Rx_space_x\",\"Rx_space_y\",\"Rx_preg\",\"g2\",\n",
    "                \"Tx_layer_space_x\",\"Tx_layer_space_y\",\n",
    "                \"Tx_current\", \"Rx_current_optimetric\"]\n",
    "\n",
    "input_cols_core = [\"freq\",\"w1\",\"l1_leg\",\"l1_top\",\"l2\",\"h1\",\"l1_center\",\n",
    "                \"Tx_turns\",\"Tx_width\",\"Tx_height\",\"Tx_space_x\",\"Tx_space_y\",\"Tx_preg\",\n",
    "                \"Rx_width\",\"Rx_height\",\"Rx_space_x\",\"Rx_space_y\",\"Rx_preg\",\"g2\",\n",
    "                \"Tx_layer_space_x\",\"Tx_layer_space_y\",\n",
    "                \"Tx_current\",\"magnetizing_current_optimetric\"]\n",
    "\n",
    "output_cols_first = [\"Lmt\",\"Llt\",\"Llr1\",\"Llr2\",\"copperloss_Tx\",\"copperloss_Rx1\",\"copperloss_Rx2\"]\n",
    "output_cols_core = [\"coreloss\",\"B_core\",\"B_left\",\"B_center\",\"B_top_left\",\"magnetizing_copperloss_Tx\",\"magnetizing_copperloss_Rx1\",\"magnetizing_copperloss_Rx2\"]\n",
    "\n",
    "\n",
    "pd_data = raw_data.dropna(axis=0,how='any')\n",
    "\n",
    "pd_data = outlier_remove(pd_data)\n",
    "\n",
    "pd_data = pd_data[(pd_data[\"B_left\"] >= 0.01)]\n",
    "pd_data = pd_data.dropna()\n",
    "\n",
    "# Finalize inputs by intersecting with available columns\n",
    "input_cols = [c for c in input_cols_copper if c in pd_data.columns]\n",
    "print(f\"Using {len(input_cols)}/{len(input_cols)} provided input columns\")\n",
    "input_core = [c for c in input_cols_core if c in pd_data.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.487562\n",
      "Best R2: 0.999991 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 7}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.136854\n",
      "Best R2: 0.999989 with params: {'n_estimators': 10000, 'learning_rate': 0.15, 'num_leaves': 7}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.945352\n",
      "Best R2: 0.999507 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.909508\n",
      "Best R2: 0.999206 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.773199\n",
      "Best R2: 0.999633 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.904936\n",
      "Best R2: 0.999934 with params: {'n_estimators': 20000, 'learning_rate': 0.1, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1.637780\n",
      "Best R2: 0.999882 with params: {'n_estimators': 20000, 'learning_rate': 0.1, 'num_leaves': 3}\n",
      "[{'target': 'Lmt', 'r2': 0.9999911499926444}, {'target': 'Llt', 'r2': 0.9999888887230244}, {'target': 'Llr1', 'r2': 0.9995072581492171}, {'target': 'Llr2', 'r2': 0.9992062935348627}, {'target': 'copperloss_Tx', 'r2': 0.9996334565486957}, {'target': 'copperloss_Rx1', 'r2': 0.9999343653995598}, {'target': 'copperloss_Rx2', 'r2': 0.9998816218383708}]\n"
     ]
    }
   ],
   "source": [
    "# Outputs: anything not in input_cols\n",
    "TARGETS = [c for c in pd_data.columns if c in output_cols_first]\n",
    "\n",
    "date = time.strftime(\"%y%m%d\")\n",
    "r2_scores = []\n",
    "\n",
    "for i in TARGETS :\n",
    "    X = pd_data[input_cols].copy()\n",
    "    Y = pd_data[i].copy()\n",
    "    model, r2_s= train_model(X,Y)\n",
    "    r2_scores.append({\"target\": i, \"r2\": r2_s})\n",
    "    joblib.dump(model, f'./model/{i}_{date}.pkl')\n",
    "\n",
    "print(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.206009\n",
      "Best R2: 0.946146 with params: {'n_estimators': 20000, 'learning_rate': 0.1, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.024060\n",
      "Best R2: 0.992112 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.097989\n",
      "Best R2: 0.991058 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -2.285946\n",
      "Best R2: 0.977495 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -0.463164\n",
      "Best R2: 0.991023 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 3.868367\n",
      "Best R2: 0.965289 with params: {'n_estimators': 20000, 'learning_rate': 0.05, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "Best R2: 0.965294 with params: {'n_estimators': 20000, 'learning_rate': 0.1, 'num_leaves': 3}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.658957\n",
      "Best R2: 0.968916 with params: {'n_estimators': 20000, 'learning_rate': 0.15, 'num_leaves': 3}\n",
      "[{'target': 'coreloss', 'r2': 0.9461458195893057}, {'target': 'B_core', 'r2': 0.9921121030716927}, {'target': 'B_left', 'r2': 0.9910577513118802}, {'target': 'B_center', 'r2': 0.9774948144448268}, {'target': 'B_top_left', 'r2': 0.9910234626168541}, {'target': 'magnetizing_copperloss_Tx', 'r2': 0.9652886593293653}, {'target': 'magnetizing_copperloss_Rx1', 'r2': 0.9652935731863261}, {'target': 'magnetizing_copperloss_Rx2', 'r2': 0.9689158915705318}]\n"
     ]
    }
   ],
   "source": [
    "# Outputs: anything not in input_cols\n",
    "TARGETS = [c for c in pd_data.columns if c in output_cols_core]\n",
    "\n",
    "date = time.strftime(\"%y%m%d\")\n",
    "r2_core_scores=[]\n",
    "for i in TARGETS :\n",
    "    X = pd_data[input_core].copy()\n",
    "    Y = pd_data[i].copy()\n",
    "    model, r2_s= train_model(X,Y)\n",
    "    r2_core_scores.append({\"target\": i, \"r2\": r2_s})\n",
    "    joblib.dump(model, f'./model/{i}_{date}.pkl')\n",
    "\n",
    "print(r2_core_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 1938, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 2.859881\n",
      "Best R2: 0.965294 with params: {'n_estimators': 20000, 'learning_rate': 0.1, 'num_leaves': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param = \"magnetizing_copperloss_Rx1\"\n",
    "X = pd_data[input_core].copy()\n",
    "Y = pd_data[param].copy()\n",
    "date = \"250919\"\n",
    "model,X_train,X_test,Y_train,Y_test= train_model_v2(X,Y)\n",
    "# joblib.dump(model, f'./model/{param}_{date}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.90751033,   3.82029077, 155.82928823,  12.48316019,\n",
       "        13.98507647])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.concat([X_train,pd.DataFrame(Y_train)], axis=1)\n",
    "\n",
    "test_data = pd.concat([X_test,pd.DataFrame(Y_test)], axis=1)\n",
    "\n",
    "\n",
    "train_data.head()\n",
    "\n",
    "\n",
    "verify_plot(model, train_data, test_data, param, xlim=[0,100], ylim=[0,100], legend=True, x_txt=\"\", y_txt=\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>w1</th>\n",
       "      <th>l1_leg</th>\n",
       "      <th>l1_top</th>\n",
       "      <th>l2</th>\n",
       "      <th>h1</th>\n",
       "      <th>l1_center</th>\n",
       "      <th>Tx_turns</th>\n",
       "      <th>Tx_width</th>\n",
       "      <th>Tx_height</th>\n",
       "      <th>Tx_space_x</th>\n",
       "      <th>Tx_space_y</th>\n",
       "      <th>Tx_preg</th>\n",
       "      <th>Rx_width</th>\n",
       "      <th>Rx_height</th>\n",
       "      <th>Rx_space_x</th>\n",
       "      <th>Rx_space_y</th>\n",
       "      <th>Rx_preg</th>\n",
       "      <th>g2</th>\n",
       "      <th>Tx_layer_space_x</th>\n",
       "      <th>Tx_layer_space_y</th>\n",
       "      <th>wire_diameter</th>\n",
       "      <th>strand_number</th>\n",
       "      <th>Tx_current</th>\n",
       "      <th>magnetizing_current_optimetric</th>\n",
       "      <th>magnetizing_copperloss_Rx1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>160.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.08</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>9.42777</td>\n",
       "      <td>11.150703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>325.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>25.1</td>\n",
       "      <td>2.76</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>14.01184</td>\n",
       "      <td>15.137108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>245.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.87</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.3871</td>\n",
       "      <td>18.08360</td>\n",
       "      <td>20.563162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>335.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>29.6</td>\n",
       "      <td>2.71</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>19.06554</td>\n",
       "      <td>16.384743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>360.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>2.79</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>22.73135</td>\n",
       "      <td>31.510653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>195.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>22.73979</td>\n",
       "      <td>22.878154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>390.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>27.4</td>\n",
       "      <td>2.43</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.16</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1649</td>\n",
       "      <td>24.78600</td>\n",
       "      <td>23.311348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>360.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>19.9</td>\n",
       "      <td>2.76</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3002</td>\n",
       "      <td>25.03072</td>\n",
       "      <td>21.895882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>185.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.17</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>25.46158</td>\n",
       "      <td>28.438728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>150.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>26.00482</td>\n",
       "      <td>29.648731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>240.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>2.90</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>28.28771</td>\n",
       "      <td>26.280372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>270.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>18.9</td>\n",
       "      <td>2.67</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>95.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>31.68665</td>\n",
       "      <td>30.993986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>95.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.57</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>83.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5356</td>\n",
       "      <td>32.20206</td>\n",
       "      <td>32.434301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>345.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>2.80</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>33.16066</td>\n",
       "      <td>37.507830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>205.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2.47</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>59.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>36.13046</td>\n",
       "      <td>47.540021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>215.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>2.57</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5128</td>\n",
       "      <td>37.87786</td>\n",
       "      <td>38.975894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>270.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.57</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>38.15481</td>\n",
       "      <td>35.671481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>325.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2.73</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>38.73569</td>\n",
       "      <td>43.659318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>305.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.34</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>39.85247</td>\n",
       "      <td>44.896960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>375.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.86</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.06</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>41.98422</td>\n",
       "      <td>34.399520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>265.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>19.2</td>\n",
       "      <td>2.47</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>42.10525</td>\n",
       "      <td>35.236642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>195.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2.88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>44.57935</td>\n",
       "      <td>45.076126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>265.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>21.9</td>\n",
       "      <td>2.60</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3019</td>\n",
       "      <td>45.27591</td>\n",
       "      <td>53.797092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>305.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.08</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1738</td>\n",
       "      <td>49.23381</td>\n",
       "      <td>43.701506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>190.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>2.76</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>50.36384</td>\n",
       "      <td>43.230588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>170.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0626</td>\n",
       "      <td>52.54796</td>\n",
       "      <td>67.344199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>325.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>25.1</td>\n",
       "      <td>2.76</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>56.04738</td>\n",
       "      <td>55.561299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>345.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>27.2</td>\n",
       "      <td>2.86</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>56.70624</td>\n",
       "      <td>67.518948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>360.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>56.90404</td>\n",
       "      <td>47.683909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>325.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>29.1</td>\n",
       "      <td>2.98</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>60.50863</td>\n",
       "      <td>66.066810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>260.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>79.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8274</td>\n",
       "      <td>62.88313</td>\n",
       "      <td>74.015082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>350.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2.43</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>64.93153</td>\n",
       "      <td>78.643261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>360.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>28.8</td>\n",
       "      <td>1.95</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.58</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>66.50368</td>\n",
       "      <td>67.736268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>400.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2.99</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.08</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>67.17572</td>\n",
       "      <td>68.477684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>220.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2.98</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>70.15578</td>\n",
       "      <td>77.225477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>330.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2.86</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>71.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>70.59628</td>\n",
       "      <td>86.511421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>185.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>29.7</td>\n",
       "      <td>2.75</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>73.74491</td>\n",
       "      <td>74.839335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>290.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2.84</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2497</td>\n",
       "      <td>74.12155</td>\n",
       "      <td>68.362665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>335.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>29.6</td>\n",
       "      <td>2.71</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.3504</td>\n",
       "      <td>76.26218</td>\n",
       "      <td>82.003721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>160.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>2.84</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5792</td>\n",
       "      <td>77.98993</td>\n",
       "      <td>89.149306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>360.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2.34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4428</td>\n",
       "      <td>78.89038</td>\n",
       "      <td>90.883679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>400.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>23.5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>79.26900</td>\n",
       "      <td>110.790958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>385.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>19.3</td>\n",
       "      <td>2.40</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4643</td>\n",
       "      <td>80.51822</td>\n",
       "      <td>82.797237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>365.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>28.9</td>\n",
       "      <td>2.79</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4831</td>\n",
       "      <td>86.92528</td>\n",
       "      <td>93.171476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>115.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2.91</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.4853</td>\n",
       "      <td>86.99712</td>\n",
       "      <td>94.734924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>355.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>28.2</td>\n",
       "      <td>2.90</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.21</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3311</td>\n",
       "      <td>90.82474</td>\n",
       "      <td>90.611772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>390.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>29.9</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>91.16133</td>\n",
       "      <td>92.868753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>175.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>91.90663</td>\n",
       "      <td>93.680441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>205.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2.43</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.64</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>93.52649</td>\n",
       "      <td>87.978662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>185.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2.66</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.08</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>94.87776</td>\n",
       "      <td>86.034622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>390.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.08</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>94.94159</td>\n",
       "      <td>95.074753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>155.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>2.58</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4643</td>\n",
       "      <td>95.06117</td>\n",
       "      <td>92.877635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>145.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2.51</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.4057</td>\n",
       "      <td>97.66239</td>\n",
       "      <td>104.506251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>340.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7671</td>\n",
       "      <td>100.61023</td>\n",
       "      <td>99.955828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>370.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>100.99092</td>\n",
       "      <td>102.712713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>260.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>23.9</td>\n",
       "      <td>2.12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5594</td>\n",
       "      <td>103.05349</td>\n",
       "      <td>122.721252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>210.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>26.8</td>\n",
       "      <td>2.64</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>103.63490</td>\n",
       "      <td>90.838040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>150.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2963</td>\n",
       "      <td>104.01927</td>\n",
       "      <td>96.631578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>130.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>104.40253</td>\n",
       "      <td>130.469435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>240.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>2.57</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>105.36335</td>\n",
       "      <td>105.837386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>340.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>26.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3378</td>\n",
       "      <td>105.71788</td>\n",
       "      <td>92.385588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>225.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>106.41764</td>\n",
       "      <td>108.726684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>150.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>107.90509</td>\n",
       "      <td>100.332141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>390.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>28.5</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>110.61702</td>\n",
       "      <td>138.920095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>195.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>24.7</td>\n",
       "      <td>2.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>85.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>110.73877</td>\n",
       "      <td>104.522098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>335.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2.71</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>111.97046</td>\n",
       "      <td>107.461235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>170.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>2.81</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.08</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3598</td>\n",
       "      <td>112.64699</td>\n",
       "      <td>107.975303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>360.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>29.3</td>\n",
       "      <td>2.37</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>112.66993</td>\n",
       "      <td>112.597605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>175.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.52</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.11</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0379</td>\n",
       "      <td>113.69324</td>\n",
       "      <td>129.027806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>380.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>2.99</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2834</td>\n",
       "      <td>113.72191</td>\n",
       "      <td>107.680912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>335.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>2.47</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>115.64036</td>\n",
       "      <td>120.296703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>225.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5896</td>\n",
       "      <td>116.04778</td>\n",
       "      <td>137.359643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>200.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>121.35658</td>\n",
       "      <td>55.894928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>155.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>28.1</td>\n",
       "      <td>2.81</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>121.42595</td>\n",
       "      <td>132.529505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>140.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.77</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.39</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>122.90848</td>\n",
       "      <td>115.797711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>320.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>2.77</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>123.30564</td>\n",
       "      <td>135.324723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>325.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>128.15191</td>\n",
       "      <td>167.816092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>210.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>128.85827</td>\n",
       "      <td>135.661454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>380.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.08</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>132.97389</td>\n",
       "      <td>164.396101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>225.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2.46</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.6714</td>\n",
       "      <td>135.87336</td>\n",
       "      <td>130.277915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>370.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>29.1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>139.49941</td>\n",
       "      <td>126.287162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>200.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>29.9</td>\n",
       "      <td>2.84</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>140.04962</td>\n",
       "      <td>183.972712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>400.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4859</td>\n",
       "      <td>140.21587</td>\n",
       "      <td>188.176181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>120.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>27.4</td>\n",
       "      <td>2.93</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.09</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1088</td>\n",
       "      <td>141.08912</td>\n",
       "      <td>137.394072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>270.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>26.3</td>\n",
       "      <td>2.55</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5120</td>\n",
       "      <td>141.49729</td>\n",
       "      <td>135.615869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>240.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2.53</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>145.03137</td>\n",
       "      <td>136.718768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>290.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2.81</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5506</td>\n",
       "      <td>146.40723</td>\n",
       "      <td>140.778227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>260.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2.99</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3129</td>\n",
       "      <td>148.38729</td>\n",
       "      <td>136.447035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>270.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.57</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>152.61926</td>\n",
       "      <td>186.048607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>23.1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.06</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0412</td>\n",
       "      <td>153.77925</td>\n",
       "      <td>201.356787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>325.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2.73</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>154.94275</td>\n",
       "      <td>183.159209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>390.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>23.2</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1978</td>\n",
       "      <td>158.87173</td>\n",
       "      <td>146.212914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>150.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.84</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3873</td>\n",
       "      <td>159.17913</td>\n",
       "      <td>163.602069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>295.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>2.79</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.47</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2040</td>\n",
       "      <td>165.71483</td>\n",
       "      <td>153.115543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>175.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2.77</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>167.56651</td>\n",
       "      <td>140.017428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>230.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.08</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>170.16833</td>\n",
       "      <td>146.425673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>355.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>27.9</td>\n",
       "      <td>1.86</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>171.47202</td>\n",
       "      <td>181.960785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>195.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2.72</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4174</td>\n",
       "      <td>173.35030</td>\n",
       "      <td>191.376364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>305.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>25.1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5394</td>\n",
       "      <td>177.52857</td>\n",
       "      <td>175.792028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>140.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>28.2</td>\n",
       "      <td>2.91</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.11</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>177.77593</td>\n",
       "      <td>169.940998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>365.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>18.1</td>\n",
       "      <td>2.66</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.8695</td>\n",
       "      <td>180.82880</td>\n",
       "      <td>218.266144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>330.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6487</td>\n",
       "      <td>182.28069</td>\n",
       "      <td>174.095063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>165.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>28.7</td>\n",
       "      <td>2.56</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7564</td>\n",
       "      <td>185.74673</td>\n",
       "      <td>161.364456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>260.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2.72</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1214</td>\n",
       "      <td>186.14906</td>\n",
       "      <td>180.917821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>115.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>29.1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3570</td>\n",
       "      <td>186.97470</td>\n",
       "      <td>230.027722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>235.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6407</td>\n",
       "      <td>187.33665</td>\n",
       "      <td>201.636512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>370.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>29.2</td>\n",
       "      <td>2.98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0197</td>\n",
       "      <td>188.48307</td>\n",
       "      <td>175.491536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>175.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9445</td>\n",
       "      <td>192.66902</td>\n",
       "      <td>182.781395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>360.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>23.9</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>195.76612</td>\n",
       "      <td>192.237543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>210.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>2.82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3441</td>\n",
       "      <td>196.08729</td>\n",
       "      <td>237.684452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>305.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.08</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>196.93523</td>\n",
       "      <td>198.135434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>190.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.52</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.17</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>200.33272</td>\n",
       "      <td>195.616015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>260.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.85</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5841</td>\n",
       "      <td>200.63012</td>\n",
       "      <td>216.870768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>360.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>2.79</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>204.58213</td>\n",
       "      <td>205.681571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>395.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>26.5</td>\n",
       "      <td>2.38</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>207.34720</td>\n",
       "      <td>218.162953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>375.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.1228</td>\n",
       "      <td>213.61448</td>\n",
       "      <td>243.246390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>130.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>29.6</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1168</td>\n",
       "      <td>213.62910</td>\n",
       "      <td>199.097535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>275.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>213.74632</td>\n",
       "      <td>204.884796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>235.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2.87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.08</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>219.52807</td>\n",
       "      <td>266.805735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>340.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2.67</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>223.31023</td>\n",
       "      <td>232.673048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>245.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.6</td>\n",
       "      <td>2.76</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>224.03710</td>\n",
       "      <td>222.505455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>400.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.08</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.8929</td>\n",
       "      <td>225.02771</td>\n",
       "      <td>228.619017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>140.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2.90</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3931</td>\n",
       "      <td>225.26580</td>\n",
       "      <td>269.912481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>360.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>19.9</td>\n",
       "      <td>2.76</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>225.27652</td>\n",
       "      <td>228.274477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>265.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3176</td>\n",
       "      <td>226.77930</td>\n",
       "      <td>285.277615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>260.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>2.93</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.91</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>227.53702</td>\n",
       "      <td>231.709368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>365.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>2.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>227.54875</td>\n",
       "      <td>257.301114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>115.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.01</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.4121</td>\n",
       "      <td>227.75658</td>\n",
       "      <td>238.504072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>180.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>29.7</td>\n",
       "      <td>2.92</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>228.04836</td>\n",
       "      <td>233.613491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>330.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>29.5</td>\n",
       "      <td>2.87</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.3639</td>\n",
       "      <td>228.69282</td>\n",
       "      <td>224.753245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>400.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.59</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>229.48111</td>\n",
       "      <td>265.381765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>195.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.70</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.1430</td>\n",
       "      <td>230.38822</td>\n",
       "      <td>235.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>260.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2.06</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4460</td>\n",
       "      <td>231.50437</td>\n",
       "      <td>256.560258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>380.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.18</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0970</td>\n",
       "      <td>232.81188</td>\n",
       "      <td>232.574853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>290.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2.84</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>234.73619</td>\n",
       "      <td>281.071607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>275.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>2.47</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>235.01472</td>\n",
       "      <td>257.118620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>320.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2.99</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.21</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4606</td>\n",
       "      <td>237.03396</td>\n",
       "      <td>265.930352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>270.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.57</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7716</td>\n",
       "      <td>238.46759</td>\n",
       "      <td>280.502491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>225.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>239.43970</td>\n",
       "      <td>240.107154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>1.85</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.17</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>243.30015</td>\n",
       "      <td>171.692168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>165.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>27.9</td>\n",
       "      <td>2.64</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>243.95378</td>\n",
       "      <td>234.724599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>380.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.76</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>250.38273</td>\n",
       "      <td>279.092837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>145.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.26</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.74</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2806</td>\n",
       "      <td>251.88231</td>\n",
       "      <td>232.634305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>215.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2.77</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>252.39138</td>\n",
       "      <td>268.444230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>90.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>26.5</td>\n",
       "      <td>2.78</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.16</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3822</td>\n",
       "      <td>252.53912</td>\n",
       "      <td>330.101372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>335.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>2.69</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.4847</td>\n",
       "      <td>253.69965</td>\n",
       "      <td>236.873783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>145.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>23.9</td>\n",
       "      <td>2.84</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>255.68962</td>\n",
       "      <td>221.904970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>265.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7031</td>\n",
       "      <td>256.16056</td>\n",
       "      <td>257.928607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>125.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>23.5</td>\n",
       "      <td>2.87</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5932</td>\n",
       "      <td>257.08511</td>\n",
       "      <td>365.982151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>265.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>22.3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7007</td>\n",
       "      <td>258.12968</td>\n",
       "      <td>321.829359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      freq     w1  l1_leg  l1_top    l2    h1  l1_center  Tx_turns  Tx_width  \\\n",
       "717  160.0   79.0     4.9     1.6  30.0  2.23       25.0       6.0      0.59   \n",
       "61   325.0   95.0     4.4     1.8  25.1  2.76        9.0       7.0      0.53   \n",
       "849  245.0  181.0     4.4     1.9  29.5  2.87       16.0       5.0      0.84   \n",
       "352  335.0  124.0     5.2     1.4  29.6  2.71       15.0       5.0      0.65   \n",
       "116  360.0   44.0     2.9     1.6  23.3  2.79        5.0      10.0      0.27   \n",
       "830  195.0   88.0     9.9     1.2  26.0  2.88       19.0       6.0      0.73   \n",
       "809  390.0  156.0     3.0     0.6  27.4  2.43        7.0       5.0      0.69   \n",
       "804  360.0   80.0     8.1     1.7  19.9  2.76       21.0       7.0      0.78   \n",
       "858  185.0   89.0     4.8     1.4  28.6  2.99       11.0       8.0      0.44   \n",
       "355  150.0  133.0     5.4     0.9  29.0  2.85       25.0       6.0      0.43   \n",
       "697  240.0  123.0     7.3     1.3  21.7  2.90       18.0       5.0      0.27   \n",
       "847  270.0  112.0     6.9     1.3  18.9  2.67       14.0       4.0      0.83   \n",
       "637   95.0  193.0     8.5     2.0  16.5  2.57       17.0       4.0      0.64   \n",
       "636  345.0   69.0     4.4     2.0  23.7  2.80       22.0       4.0      0.50   \n",
       "692  205.0   71.0    14.4     1.3  26.7  2.47       14.0       7.0      0.65   \n",
       "414  215.0  195.0     7.5     2.0  28.5  2.57       16.0       4.0      0.53   \n",
       "221  270.0   60.0     4.6     1.3  25.6  2.57       12.0      11.0      0.37   \n",
       "316  325.0   68.0    11.7     1.9  28.4  2.73       16.0       6.0      0.64   \n",
       "102  305.0   68.0     2.9     1.8  25.0  2.34        8.0       4.0      0.47   \n",
       "310  375.0   76.0     7.0     1.8  28.8  2.86       11.0      10.0      0.68   \n",
       "49   265.0   68.0     9.8     1.6  19.2  2.47       23.0       8.0      0.48   \n",
       "695  195.0   73.0    11.7     1.9  27.1  2.88        5.0       8.0      0.55   \n",
       "298  265.0   85.0     4.1     1.1  21.9  2.60       19.0       7.0      0.23   \n",
       "700  305.0   85.0     7.1     0.8  24.0  2.79       18.0       4.0      0.63   \n",
       "508  190.0   63.0     3.6     1.9  23.4  2.76       20.0       5.0      0.58   \n",
       "751  170.0  132.0     8.0     2.0  24.7  2.80        7.0       3.0      0.43   \n",
       "527  325.0   95.0     4.4     1.8  25.1  2.76        9.0       7.0      0.53   \n",
       "192  345.0   56.0     5.3     1.8  27.2  2.86       18.0       6.0      0.64   \n",
       "532  360.0   83.0     5.7     1.1  30.0  2.69       23.0       7.0      0.35   \n",
       "416  325.0  125.0    14.1     1.7  29.1  2.98       22.0       6.0      0.67   \n",
       "104  260.0  192.0     9.1     1.3  21.5  2.89       10.0       4.0      0.63   \n",
       "181  350.0  103.0     4.7     1.2  28.6  2.43       13.0       4.0      0.25   \n",
       "868  360.0   64.0     6.6     1.5  28.8  1.95       18.0       6.0      0.33   \n",
       "68   400.0   73.0    12.0     0.6  27.8  2.99        8.0       4.0      0.57   \n",
       "451  220.0   82.0    12.5     2.0  27.8  2.98       11.0       8.0      0.44   \n",
       "271  330.0   95.0     4.8     0.5  28.4  2.86       12.0       5.0      0.95   \n",
       "38   185.0   54.0    14.6     0.9  29.7  2.75        7.0       8.0      0.54   \n",
       "896  290.0  124.0    11.2     1.9  28.4  2.84       18.0       5.0      0.46   \n",
       "230  335.0  124.0     5.2     1.4  29.6  2.71       15.0       5.0      0.65   \n",
       "666  160.0  149.0     8.8     0.8  20.9  2.84       13.0       5.0      0.22   \n",
       "322  360.0   39.0     3.6     2.0  26.7  2.34        9.0       5.0      0.70   \n",
       "183  400.0  180.0     8.4     1.2  23.5  2.99       22.0       2.0      0.79   \n",
       "222  385.0   39.0    10.4     1.8  19.3  2.40       13.0       6.0      0.62   \n",
       "894  365.0  132.0     3.2     0.9  28.9  2.79       19.0       5.0      0.47   \n",
       "556  115.0  108.0     2.1     1.6  18.5  2.91       22.0       3.0      0.85   \n",
       "48   355.0   24.0    12.3     1.3  28.2  2.90       24.0      11.0      0.60   \n",
       "95   390.0  153.0     8.8     1.4  29.9  2.02        1.0       6.0      0.25   \n",
       "197  175.0  157.0     2.5     1.0  25.6  2.61        4.0       5.0      0.69   \n",
       "47   205.0  136.0     8.5     1.8  27.1  2.43       20.0       5.0      0.50   \n",
       "430  185.0   21.0     6.8     1.8  27.8  2.66       17.0      14.0      0.41   \n",
       "180  390.0   79.0     6.9     1.4  23.0  2.24       16.0       4.0      0.57   \n",
       "459  155.0  185.0     5.7     1.0  26.4  2.58        8.0       4.0      0.59   \n",
       "237  145.0  116.0     3.2     1.8  15.6  2.51       16.0       5.0      0.30   \n",
       "58   340.0   40.0    10.9     0.9  25.0  2.50        8.0       3.0      0.31   \n",
       "665  370.0  110.0     4.0     1.0  28.3  2.73       23.0       4.0      0.56   \n",
       "397  260.0   86.0    13.4     1.2  23.9  2.12       14.0       4.0      0.58   \n",
       "798  210.0  130.0     2.5     0.5  26.8  2.64       24.0       7.0      0.61   \n",
       "457  150.0  133.0     5.4     0.9  29.0  2.85       25.0       6.0      0.43   \n",
       "235  130.0   49.0    10.7     0.6  29.4  2.40        8.0      10.0      0.37   \n",
       "612  240.0   92.0     3.7     1.0  29.6  2.57       25.0       5.0      0.84   \n",
       "223  340.0   56.0    12.9     1.1  26.3  2.94       23.0      11.0      0.55   \n",
       "60   225.0   83.0     9.9     2.0  26.1  2.85       17.0       6.0      0.50   \n",
       "218  150.0   48.0     2.1     1.1  26.5  2.28       18.0       6.0      0.23   \n",
       "1    390.0  170.0     4.4     0.7  28.5  2.93        5.0       8.0      0.67   \n",
       "383  195.0   54.0     7.8     1.9  24.7  2.56       21.0      10.0      0.65   \n",
       "314  335.0  156.0     9.1     0.8  29.4  2.71       18.0       4.0      0.60   \n",
       "579  170.0  140.0    10.9     2.0  26.1  2.81       17.0       5.0      0.41   \n",
       "365  360.0   20.0     4.9     1.7  29.3  2.37       19.0       6.0      0.54   \n",
       "616  175.0   88.0     3.4     1.1  28.0  2.52       24.0       4.0      0.65   \n",
       "683  380.0   88.0     3.6     0.6  19.4  2.99       10.0       8.0      0.92   \n",
       "250  335.0  109.0     6.3     1.4  24.4  2.47       12.0       4.0      0.43   \n",
       "385  225.0   67.0     9.7     0.7  26.0  2.39       20.0       6.0      0.57   \n",
       "154  200.0   45.0     3.2     1.2  28.0  2.59       23.0      10.0      0.53   \n",
       "744  155.0   73.0     8.9     1.2  28.1  2.81       17.0       5.0      0.47   \n",
       "589  140.0  108.0    12.9     1.2  29.5  2.77        9.0       5.0      0.35   \n",
       "421  320.0   62.0     8.8     2.0  29.3  2.77        7.0       5.0      0.23   \n",
       "188  325.0   23.0    14.8     0.6  22.0  2.06       14.0      13.0      0.66   \n",
       "677  210.0   86.0    13.8     1.3  23.0  2.76        3.0       7.0      0.80   \n",
       "262  380.0  166.0    10.2     1.1  27.5  2.65        4.0       4.0      0.57   \n",
       "675  225.0  195.0     3.9     1.1  17.6  2.46        7.0       3.0      0.29   \n",
       "178  370.0  131.0     8.7     1.8  29.1  2.92       20.0       4.0      0.75   \n",
       "401  200.0   54.0    13.4     1.6  29.9  2.84        7.0       5.0      0.66   \n",
       "808  400.0   87.0     7.5     0.8  28.8  2.56        1.0       6.0      0.63   \n",
       "369  120.0   89.0    15.0     1.5  27.4  2.93       15.0       4.0      0.64   \n",
       "766  270.0   53.0     5.6     1.9  26.3  2.55       15.0       6.0      0.49   \n",
       "434  240.0  148.0     7.7     2.0  27.5  2.53       21.0       7.0      0.36   \n",
       "27   290.0   26.0    14.1     1.8  29.4  2.81       20.0       4.0      0.64   \n",
       "206  260.0   28.0     3.8     1.1  25.7  2.99       25.0       5.0      0.54   \n",
       "603  270.0   60.0     4.6     1.3  25.6  2.57       12.0      11.0      0.37   \n",
       "209  210.0  178.0    14.8     1.8  23.1  2.42        1.0       6.0      0.67   \n",
       "507  325.0   68.0    11.7     1.9  28.4  2.73       16.0       6.0      0.64   \n",
       "309  390.0  104.0     2.9     1.1  23.2  2.81        5.0       5.0      0.48   \n",
       "291  150.0   46.0    10.3     0.9  30.0  2.84       12.0       8.0      0.25   \n",
       "396  295.0   33.0    14.9     2.0  20.4  2.79        6.0       7.0      0.45   \n",
       "546  175.0   62.0     9.8     1.1  29.4  2.77       20.0       9.0      0.49   \n",
       "354  230.0   69.0     5.0     1.0  24.0  2.77       14.0       7.0      0.94   \n",
       "703  355.0   24.0    13.8     1.7  27.9  1.86       13.0       8.0      0.32   \n",
       "285  195.0  121.0    12.0     2.0  27.5  2.72       22.0       5.0      0.44   \n",
       "777  305.0  168.0     9.5     1.9  25.1  3.00        5.0       4.0      0.34   \n",
       "407  140.0  132.0     8.4     1.9  28.2  2.91       22.0      11.0      0.34   \n",
       "467  365.0  149.0     8.6     1.9  18.1  2.66        6.0       2.0      0.65   \n",
       "172  330.0   46.0    13.6     1.3  27.2  1.79        2.0      10.0      0.32   \n",
       "115  165.0  155.0     6.1     1.1  28.7  2.56       18.0       4.0      0.37   \n",
       "646  260.0  183.0    10.4     1.2  13.6  2.72        6.0       2.0      0.61   \n",
       "898  115.0  109.0     2.6     1.8  29.1  3.00        4.0       5.0      0.60   \n",
       "887  235.0   94.0    13.1     1.1  17.5  2.99       20.0       7.0      0.44   \n",
       "781  370.0   51.0     4.3     1.3  29.2  2.98        5.0       6.0      0.65   \n",
       "106  175.0  186.0     6.8     1.1  23.1  2.92       18.0       2.0      0.59   \n",
       "64   360.0   81.0    11.8     1.2  23.9  2.66       10.0       5.0      0.53   \n",
       "198  210.0  118.0     7.4     0.6  20.7  2.82       22.0       5.0      0.45   \n",
       "488  305.0   85.0     7.1     0.8  24.0  2.79       18.0       4.0      0.63   \n",
       "892  190.0  147.0     3.7     1.1  28.8  2.52       24.0       3.0      0.38   \n",
       "304  260.0   81.0     8.1     1.9  21.5  2.85       22.0       7.0      0.28   \n",
       "796  360.0   44.0     2.9     1.6  23.3  2.79        5.0      10.0      0.27   \n",
       "626  395.0  107.0     7.0     1.6  26.5  2.38        6.0       4.0      0.37   \n",
       "239  375.0  144.0    12.5     0.8  24.9  2.96        7.0       3.0      0.47   \n",
       "55   130.0   86.0     8.6     1.8  29.6  2.75        3.0       7.0      0.61   \n",
       "18   275.0  159.0     6.2     1.7  28.8  2.96        3.0       3.0      0.46   \n",
       "160  235.0   47.0    12.2     2.0  25.9  2.87       15.0       9.0      0.45   \n",
       "329  340.0   37.0     5.0     1.3  27.5  2.67       15.0       4.0      0.59   \n",
       "289  245.0   27.0    12.8     1.9  27.6  2.76       22.0      11.0      0.43   \n",
       "238  400.0   26.0    10.2     1.3  21.0  2.94       13.0       5.0      0.41   \n",
       "712  140.0  121.0     4.3     1.9  25.8  2.90       23.0       4.0      0.44   \n",
       "702  360.0   80.0     8.1     1.7  19.9  2.76       21.0       7.0      0.78   \n",
       "444  265.0  161.0    13.1     1.8  16.1  2.91        4.0       3.0      0.30   \n",
       "80   260.0   39.0    14.7     1.7  20.6  2.93       16.0      14.0      0.38   \n",
       "52   365.0   42.0     8.6     2.0  23.1  2.96        3.0       7.0      0.33   \n",
       "701  115.0  109.0    11.5     1.2  21.3  2.01       21.0       6.0      0.23   \n",
       "740  180.0   99.0     7.2     1.5  29.7  2.92       17.0       6.0      0.60   \n",
       "5    330.0  181.0     5.1     1.2  29.5  2.87        9.0       4.0      0.63   \n",
       "226  400.0  146.0     8.4     1.8  18.7  2.59       14.0       4.0      0.37   \n",
       "152  195.0  141.0     5.1     1.8  15.5  2.70        8.0       4.0      0.44   \n",
       "900  260.0  179.0    12.0     1.0  14.1  2.06       22.0       3.0      0.22   \n",
       "642  380.0  118.0     3.0     1.5  28.0  2.03       14.0       3.0      0.27   \n",
       "872  290.0  124.0    11.2     1.9  28.4  2.84       18.0       5.0      0.46   \n",
       "718  275.0   54.0     9.4     1.0  18.8  2.47       20.0       6.0      0.48   \n",
       "85   320.0  200.0     8.8     1.9  26.7  2.99       10.0       2.0      0.60   \n",
       "518  270.0   60.0     4.6     1.3  25.6  2.57       12.0      11.0      0.37   \n",
       "652  225.0   83.0     9.9     2.0  26.1  2.85       17.0       6.0      0.50   \n",
       "190  190.0  165.0     3.1     0.7  29.7  1.85       18.0       5.0      0.37   \n",
       "168  165.0  123.0    10.3     1.7  27.9  2.64       12.0       9.0      0.73   \n",
       "680  380.0   71.0    13.5     0.5  18.7  2.76       15.0       7.0      0.39   \n",
       "821  145.0  168.0     8.0     1.5  26.5  2.76       24.0       5.0      0.61   \n",
       "679  215.0   40.0     4.9     1.1  27.5  2.77       21.0      10.0      0.65   \n",
       "261   90.0   83.0    11.5     1.6  26.5  2.78       25.0       5.0      0.25   \n",
       "572  335.0   70.0     5.5     0.6  23.1  2.69       20.0       3.0      0.33   \n",
       "167  145.0   97.0     8.3     1.1  23.9  2.84       21.0       8.0      0.49   \n",
       "632  265.0  135.0    12.9     1.0  27.3  2.75       21.0       3.0      0.43   \n",
       "189  125.0   37.0     6.7     1.7  23.5  2.87        4.0       7.0      0.64   \n",
       "324  265.0   64.0     7.4     1.4  22.3  2.73       14.0       6.0      0.73   \n",
       "\n",
       "     Tx_height  Tx_space_x  Tx_space_y  Tx_preg  Rx_width  Rx_height  \\\n",
       "717       0.59         2.7         5.0     0.23       7.7        0.2   \n",
       "61        0.53         4.7         1.1     0.10       8.2        0.2   \n",
       "849       0.84         3.7         4.2     0.24       5.9        0.2   \n",
       "352       0.65         1.3         3.5     0.13      15.1        0.2   \n",
       "116       0.27         3.9         5.0     0.27       8.3        0.2   \n",
       "830       0.73         4.0         4.7     0.09       7.7        0.2   \n",
       "809       0.69         0.3         0.8     0.16      13.4        0.3   \n",
       "804       0.78         2.5         3.3     0.08       4.2        0.3   \n",
       "858       0.44         4.5         3.3     0.17       4.6        0.1   \n",
       "355       0.43         0.1         1.8     0.22      10.3        0.6   \n",
       "697       0.27         4.6         4.0     0.30       5.7        0.8   \n",
       "847       0.83         0.3         1.0     0.08       4.5        0.3   \n",
       "637       0.64         2.6         1.3     0.12       6.6        0.2   \n",
       "636       0.50         4.9         4.6     0.24       6.4        0.5   \n",
       "692       0.65         4.0         1.6     0.11       5.6        0.4   \n",
       "414       0.53         1.8         4.6     0.11       5.0        0.2   \n",
       "221       0.37         0.2         2.5     0.06       5.4        0.2   \n",
       "316       0.64         3.7         1.4     0.07       8.6        0.4   \n",
       "102       0.47         3.8         0.6     0.11       8.4        0.1   \n",
       "310       0.68         1.7         2.6     0.27       4.8        0.2   \n",
       "49        0.48         1.3         1.8     0.20       6.1        0.3   \n",
       "695       0.55         1.0         2.0     0.19       7.2        0.3   \n",
       "298       0.23         2.5         0.2     0.08       9.6        0.6   \n",
       "700       0.63         4.8         2.7     0.16       6.0        0.1   \n",
       "508       0.58         0.9         3.1     0.21       6.0        0.1   \n",
       "751       0.43         4.4         4.4     0.29       4.5        0.4   \n",
       "527       0.53         4.7         1.1     0.10       8.2        0.2   \n",
       "192       0.64         4.3         4.5     0.10       5.6        0.2   \n",
       "532       0.35         4.2         4.1     0.05       4.8        0.3   \n",
       "416       0.67         4.3         1.4     0.07       4.6        0.4   \n",
       "104       0.63         2.5         1.4     0.12       8.5        0.5   \n",
       "181       0.25         2.6         3.9     0.23       5.4        0.2   \n",
       "868       0.33         3.2         4.3     0.13       8.9        0.1   \n",
       "68        0.57         0.5         3.0     0.17       5.8        0.5   \n",
       "451       0.44         2.2         0.4     0.14       5.0        0.1   \n",
       "271       0.95         0.2         2.2     0.21       9.3        0.2   \n",
       "38        0.54         3.0         0.2     0.18       4.0        0.3   \n",
       "896       0.46         0.8         4.2     0.16       9.5        0.2   \n",
       "230       0.65         1.3         3.5     0.13      15.1        0.2   \n",
       "666       0.22         0.9         0.1     0.11       8.1        0.5   \n",
       "322       0.70         2.9         1.7     0.08       5.4        0.1   \n",
       "183       0.79         1.3         0.8     0.29      13.4        0.4   \n",
       "222       0.62         1.6         1.7     0.05       6.3        0.2   \n",
       "894       0.47         3.8         2.8     0.18       4.2        0.4   \n",
       "556       0.85         3.1         2.2     0.06       5.5        0.5   \n",
       "48        0.60         0.8         3.8     0.21      11.8        0.1   \n",
       "95        0.25         1.0         1.5     0.14       5.5        0.3   \n",
       "197       0.69         4.2         3.9     0.06      12.0        0.3   \n",
       "47        0.50         0.6         2.7     0.22       8.7        0.2   \n",
       "430       0.41         1.4         0.7     0.24       6.8        0.2   \n",
       "180       0.57         1.0         4.3     0.27      10.6        0.1   \n",
       "459       0.59         4.0         4.6     0.16      10.8        0.2   \n",
       "237       0.30         0.8         1.6     0.05       6.9        0.1   \n",
       "58        0.31         1.3         1.3     0.08       8.7        0.5   \n",
       "665       0.56         0.9         3.1     0.19      13.9        0.4   \n",
       "397       0.58         2.0         3.4     0.24      11.4        0.2   \n",
       "798       0.61         4.5         1.6     0.11       4.7        0.2   \n",
       "457       0.43         0.1         1.8     0.22      10.3        0.6   \n",
       "235       0.37         2.0         3.9     0.29       7.6        0.4   \n",
       "612       0.84         4.8         0.8     0.12      10.7        0.2   \n",
       "223       0.55         0.9         1.0     0.16       5.4        0.3   \n",
       "60        0.50         0.3         3.1     0.07       7.7        0.1   \n",
       "218       0.23         3.8         2.9     0.19       7.8        0.5   \n",
       "1         0.67         0.3         3.2     0.09      13.8        0.3   \n",
       "383       0.65         3.9         2.7     0.09      10.3        0.1   \n",
       "314       0.60         4.9         0.6     0.21       5.0        0.1   \n",
       "579       0.41         2.1         3.2     0.06      11.3        0.2   \n",
       "365       0.54         0.4         3.4     0.16       7.1        0.3   \n",
       "616       0.65         1.7         4.7     0.11       5.1        0.2   \n",
       "683       0.92         3.7         2.5     0.22       4.9        0.2   \n",
       "250       0.43         5.0         2.2     0.22       6.2        0.2   \n",
       "385       0.57         4.2         4.5     0.06       5.6        0.4   \n",
       "154       0.53         2.6         3.9     0.19       7.3        0.2   \n",
       "744       0.47         0.8         1.9     0.07      15.0        0.2   \n",
       "589       0.35         3.6         4.4     0.13       4.9        0.2   \n",
       "421       0.23         4.1         3.3     0.09      13.5        0.8   \n",
       "188       0.66         2.5         0.5     0.16       4.1        0.1   \n",
       "677       0.80         4.2         0.5     0.21       4.1        0.2   \n",
       "262       0.57         1.1         1.2     0.26       4.5        0.1   \n",
       "675       0.29         3.4         1.6     0.18       6.0        0.5   \n",
       "178       0.75         2.1         3.3     0.28      11.5        0.1   \n",
       "401       0.66         4.8         0.4     0.20      15.9        0.3   \n",
       "808       0.63         1.2         3.9     0.24      11.2        0.1   \n",
       "369       0.64         3.9         2.7     0.09       6.4        0.4   \n",
       "766       0.49         3.4         4.8     0.28       6.0        0.1   \n",
       "434       0.36         3.1         1.5     0.26       4.1        0.2   \n",
       "27        0.64         0.3         2.4     0.06       6.4        0.4   \n",
       "206       0.54         3.0         3.7     0.24       7.7        0.3   \n",
       "603       0.37         0.2         2.5     0.06       5.4        0.2   \n",
       "209       0.67         3.7         3.8     0.07       6.5        0.2   \n",
       "507       0.64         3.7         1.4     0.07       8.6        0.4   \n",
       "309       0.48         0.2         2.4     0.09       7.1        0.4   \n",
       "291       0.25         3.0         1.6     0.09      10.2        0.2   \n",
       "396       0.45         3.9         1.3     0.15       4.2        0.6   \n",
       "546       0.49         0.8         1.5     0.07       4.1        0.2   \n",
       "354       0.94         0.3         2.8     0.23       4.9        0.1   \n",
       "703       0.32         3.9         4.8     0.07       7.8        0.1   \n",
       "285       0.44         0.5         3.4     0.12       4.1        0.4   \n",
       "777       0.34         2.5         1.6     0.10       8.3        0.5   \n",
       "407       0.34         4.4         4.2     0.11       5.1        0.3   \n",
       "467       0.65         3.3         2.9     0.18       5.6        0.3   \n",
       "172       0.32         0.3         1.6     0.24       5.1        0.3   \n",
       "115       0.37         4.7         5.0     0.29       8.1        0.3   \n",
       "646       0.61         2.2         4.4     0.08       4.1        0.3   \n",
       "898       0.60         2.5         4.9     0.10       5.0        0.3   \n",
       "887       0.44         2.6         1.7     0.25       4.5        0.3   \n",
       "781       0.65         4.5         1.2     0.12       5.1        0.3   \n",
       "106       0.59         3.5         3.6     0.07      12.8        0.2   \n",
       "64        0.53         1.2         2.3     0.26      10.4        0.1   \n",
       "198       0.45         1.1         4.2     0.16       7.1        0.3   \n",
       "488       0.63         4.8         2.7     0.16       6.0        0.1   \n",
       "892       0.38         3.9         1.3     0.17      14.4        0.1   \n",
       "304       0.28         3.9         1.8     0.07       7.3        0.2   \n",
       "796       0.27         3.9         5.0     0.27       8.3        0.2   \n",
       "626       0.37         4.0         4.4     0.06       9.7        0.4   \n",
       "239       0.47         3.8         0.4     0.20       5.6        0.5   \n",
       "55        0.61         0.6         4.7     0.17       7.8        0.1   \n",
       "18        0.46         2.8         1.4     0.12       5.6        0.4   \n",
       "160       0.45         1.3         3.9     0.08       7.6        0.1   \n",
       "329       0.59         4.4         2.1     0.09      11.1        0.1   \n",
       "289       0.43         2.0         3.7     0.18       6.4        0.1   \n",
       "238       0.41         3.9         1.0     0.16       4.8        0.7   \n",
       "712       0.44         3.7         4.3     0.19       4.0        0.4   \n",
       "702       0.78         2.5         3.3     0.08       4.2        0.3   \n",
       "444       0.30         1.0         4.3     0.28       7.4        0.2   \n",
       "80        0.38         3.6         2.2     0.12       4.2        0.1   \n",
       "52        0.33         1.5         4.6     0.07       5.4        0.1   \n",
       "701       0.23         1.3         3.8     0.17       6.4        0.5   \n",
       "740       0.60         1.6         4.5     0.22      16.8        0.5   \n",
       "5         0.63         5.0         1.9     0.07       8.3        0.3   \n",
       "226       0.37         3.8         0.8     0.16      10.2        0.2   \n",
       "152       0.44         2.9         4.9     0.12       4.0        0.1   \n",
       "900       0.22         4.2         1.5     0.27       4.6        0.1   \n",
       "642       0.27         1.2         3.5     0.18       8.4        0.3   \n",
       "872       0.46         0.8         4.2     0.16       9.5        0.2   \n",
       "718       0.48         3.6         0.5     0.26       4.7        0.1   \n",
       "85        0.60         4.3         4.4     0.21      15.7        0.6   \n",
       "518       0.37         0.2         2.5     0.06       5.4        0.2   \n",
       "652       0.50         0.3         3.1     0.07       7.7        0.1   \n",
       "190       0.37         4.8         3.6     0.17      13.8        0.1   \n",
       "168       0.73         1.3         4.8     0.14       7.3        0.1   \n",
       "680       0.39         1.7         2.0     0.16       5.0        0.2   \n",
       "821       0.61         3.8         1.9     0.26      10.4        0.2   \n",
       "679       0.65         1.0         3.0     0.17       9.6        0.4   \n",
       "261       0.25         4.2         0.8     0.16      17.1        0.6   \n",
       "572       0.33         3.6         4.1     0.25      11.4        0.8   \n",
       "167       0.49         2.3         4.3     0.17       8.4        0.1   \n",
       "632       0.43         2.9         3.9     0.07       6.2        0.6   \n",
       "189       0.64         2.3         2.6     0.09       7.2        0.4   \n",
       "324       0.73         4.4         1.3     0.16       9.4        0.2   \n",
       "\n",
       "     Rx_space_x  Rx_space_y  Rx_preg    g2  Tx_layer_space_x  \\\n",
       "717         1.4         4.7     0.07  0.54               4.4   \n",
       "61          2.0         3.6     0.10  0.73               3.7   \n",
       "849         1.8         3.8     0.08  2.38               3.8   \n",
       "352         4.5         5.0     0.06  0.62               2.7   \n",
       "116         0.9         3.4     0.26  2.74               0.6   \n",
       "830         1.6         1.5     0.08  0.19               2.0   \n",
       "809         4.5         2.7     0.05  0.49               0.9   \n",
       "804         4.4         0.4     0.15  1.29               2.3   \n",
       "858         4.4         3.9     0.14  2.00               2.0   \n",
       "355         4.2         1.8     0.16  0.64               0.7   \n",
       "697         2.1         3.9     0.06  1.38               3.3   \n",
       "847         1.3         1.7     0.07  1.32               3.8   \n",
       "637         0.1         2.6     0.11  1.35               0.7   \n",
       "636         4.5         4.0     0.09  2.31               0.9   \n",
       "692         1.1         5.0     0.12  0.82               0.4   \n",
       "414         0.1         3.7     0.11  2.47               0.9   \n",
       "221         1.1         4.0     0.09  0.94               0.7   \n",
       "316         4.9         2.8     0.09  1.51               3.9   \n",
       "102         2.3         2.0     0.07  0.52               4.8   \n",
       "310         4.8         3.9     0.10  1.14               0.8   \n",
       "49          0.7         0.2     0.17  0.43               3.3   \n",
       "695         4.8         2.1     0.14  1.27               2.2   \n",
       "298         1.7         0.6     0.11  0.85               3.0   \n",
       "700         4.5         1.1     0.17  0.15               3.6   \n",
       "508         2.5         2.2     0.13  0.92               4.6   \n",
       "751         4.4         2.9     0.14  1.20               0.7   \n",
       "527         2.0         3.6     0.10  0.73               3.7   \n",
       "192         1.2         1.0     0.28  1.83               1.0   \n",
       "532         0.9         4.8     0.08  1.11               2.6   \n",
       "416         1.3         4.1     0.14  2.95               2.4   \n",
       "104         0.8         0.3     0.09  1.38               0.8   \n",
       "181         4.3         0.2     0.25  0.85               1.8   \n",
       "868         0.5         0.8     0.15  0.58               4.3   \n",
       "68          3.9         0.5     0.12  1.16               0.4   \n",
       "451         2.2         2.3     0.19  2.72               1.2   \n",
       "271         0.4         0.6     0.10  0.15               2.0   \n",
       "38          2.8         0.7     0.12  0.21               3.3   \n",
       "896         4.2         1.3     0.05  0.23               4.0   \n",
       "230         4.5         5.0     0.06  0.62               2.7   \n",
       "666         0.6         4.2     0.25  0.62               3.4   \n",
       "322         0.5         0.8     0.07  0.54               4.1   \n",
       "183         1.5         4.2     0.06  0.51               2.3   \n",
       "222         0.2         1.4     0.16  0.90               4.8   \n",
       "894         4.2         1.9     0.14  1.20               2.7   \n",
       "556         2.5         3.9     0.05  1.76               1.9   \n",
       "48          1.3         2.6     0.28  2.11               0.2   \n",
       "95          3.4         1.6     0.18  0.40               0.7   \n",
       "197         1.4         3.9     0.11  0.29               1.2   \n",
       "47          1.9         4.2     0.17  1.64               4.3   \n",
       "430         0.2         0.6     0.07  0.71               0.2   \n",
       "180         4.2         2.6     0.11  0.72               1.9   \n",
       "459         1.5         4.1     0.22  0.62               4.2   \n",
       "237         3.9         2.3     0.19  0.70               3.1   \n",
       "58          3.9         2.4     0.27  0.32               0.6   \n",
       "665         3.8         1.8     0.14  1.45               0.4   \n",
       "397         0.5         3.8     0.12  0.51               0.3   \n",
       "798         2.4         1.6     0.16  1.05               3.7   \n",
       "457         4.2         1.8     0.16  0.64               0.7   \n",
       "235         2.0         2.6     0.28  1.35               0.6   \n",
       "612         2.7         2.7     0.14  2.17               0.3   \n",
       "223         4.9         1.4     0.17  1.69               1.6   \n",
       "60          4.2         4.7     0.14  0.96               1.0   \n",
       "218         5.0         4.5     0.05  2.24               0.5   \n",
       "1           1.2         2.2     0.27  1.11               4.0   \n",
       "383         4.2         0.6     0.14  1.58               2.9   \n",
       "314         4.1         3.3     0.22  2.54               2.1   \n",
       "579         2.8         3.2     0.15  0.43               4.3   \n",
       "365         4.6         0.2     0.26  1.69               2.3   \n",
       "616         3.1         1.8     0.23  1.76               2.3   \n",
       "683         3.0         1.0     0.08  0.34               2.4   \n",
       "250         2.7         4.9     0.05  0.78               3.2   \n",
       "385         4.3         4.4     0.14  1.44               1.4   \n",
       "154         4.6         3.4     0.18  0.35               2.9   \n",
       "744         1.7         3.1     0.08  0.14               1.8   \n",
       "589         2.6         0.3     0.06  2.39               1.3   \n",
       "421         2.4         0.6     0.07  0.26               0.8   \n",
       "188         3.4         1.3     0.12  1.13               0.3   \n",
       "677         2.3         3.7     0.18  0.12               2.5   \n",
       "262         1.8         4.0     0.07  0.26               3.2   \n",
       "675         2.5         3.8     0.12  1.26               4.0   \n",
       "178         2.0         2.2     0.06  2.85               3.8   \n",
       "401         0.6         0.5     0.16  0.14               1.8   \n",
       "808         2.5         1.3     0.06  0.86               2.2   \n",
       "369         3.2         5.0     0.07  0.41               2.5   \n",
       "766         0.1         2.9     0.09  1.20               3.0   \n",
       "434         2.7         1.2     0.21  2.32               4.0   \n",
       "27          3.7         3.4     0.14  2.17               3.7   \n",
       "206         4.7         1.4     0.07  0.16               1.7   \n",
       "603         1.1         4.0     0.09  0.94               0.7   \n",
       "209         3.4         1.6     0.07  1.11               2.8   \n",
       "507         4.9         2.8     0.09  1.51               3.9   \n",
       "309         3.3         1.6     0.14  2.38               0.7   \n",
       "291         5.0         4.3     0.07  0.85               2.2   \n",
       "396         4.1         2.9     0.12  2.47               4.9   \n",
       "546         2.0         2.2     0.21  2.00               0.8   \n",
       "354         0.3         2.2     0.21  0.40               3.4   \n",
       "703         1.7         4.4     0.26  0.23               2.3   \n",
       "285         3.5         4.5     0.27  0.25               2.9   \n",
       "777         3.4         3.5     0.22  0.84               1.3   \n",
       "407         0.6         0.6     0.13  2.82               1.3   \n",
       "467         2.7         2.8     0.20  0.38               1.8   \n",
       "172         2.6         2.4     0.07  1.04               2.8   \n",
       "115         2.0         3.3     0.06  1.54               0.7   \n",
       "646         0.1         0.9     0.29  1.02               2.5   \n",
       "898         3.4         1.1     0.10  0.64               1.5   \n",
       "887         4.0         1.3     0.09  1.79               2.8   \n",
       "781         4.1         1.6     0.07  1.01               1.4   \n",
       "106         0.4         3.8     0.28  1.09               3.4   \n",
       "64          3.0         3.8     0.05  0.89               4.2   \n",
       "198         4.4         2.8     0.15  0.35               2.4   \n",
       "488         4.5         1.1     0.17  0.15               3.6   \n",
       "892         5.0         4.3     0.05  1.17               1.9   \n",
       "304         3.9         0.4     0.05  2.63               2.5   \n",
       "796         0.9         3.4     0.26  2.74               0.6   \n",
       "626         3.2         0.7     0.20  0.73               5.0   \n",
       "239         0.6         3.6     0.10  2.62               3.2   \n",
       "55          4.4         3.3     0.09  2.54               1.7   \n",
       "18          2.2         0.2     0.15  0.22               4.8   \n",
       "160         4.7         2.8     0.18  1.56               2.2   \n",
       "329         3.2         4.1     0.14  0.36               3.2   \n",
       "289         1.0         1.3     0.14  1.24               0.3   \n",
       "238         3.4         2.6     0.17  0.78               2.3   \n",
       "712         0.5         1.6     0.27  2.18               0.7   \n",
       "702         4.4         0.4     0.15  1.29               2.3   \n",
       "444         1.2         2.5     0.07  0.44               1.6   \n",
       "80          1.9         3.1     0.22  2.91               1.2   \n",
       "52          1.2         0.9     0.28  1.51               1.5   \n",
       "701         3.4         2.1     0.05  0.29               2.9   \n",
       "740         0.5         1.2     0.09  0.60               3.8   \n",
       "5           2.9         2.4     0.15  2.23               0.6   \n",
       "226         3.3         0.1     0.18  1.26               0.8   \n",
       "152         3.9         2.2     0.21  0.96               3.5   \n",
       "900         4.4         1.1     0.17  0.79               0.6   \n",
       "642         4.4         2.6     0.14  1.47               1.8   \n",
       "872         4.2         1.3     0.05  0.23               4.0   \n",
       "718         0.3         4.8     0.22  1.39               0.9   \n",
       "85          3.3         1.1     0.19  1.00               2.7   \n",
       "518         1.1         4.0     0.09  0.94               0.7   \n",
       "652         4.2         4.7     0.14  0.96               1.0   \n",
       "190         2.6         0.7     0.30  0.33               3.9   \n",
       "168         4.7         0.7     0.21  2.07               3.4   \n",
       "680         2.2         0.3     0.20  2.17               2.9   \n",
       "821         2.9         3.9     0.07  2.74               1.9   \n",
       "679         1.5         1.9     0.06  2.02               1.0   \n",
       "261         3.6         0.3     0.19  0.17               3.2   \n",
       "572         0.3         2.4     0.05  2.22               2.1   \n",
       "167         3.3         1.0     0.13  2.58               2.9   \n",
       "632         0.8         0.7     0.05  0.23               4.3   \n",
       "189         4.3         1.8     0.15  0.50               1.1   \n",
       "324         1.6         2.2     0.24  0.73               4.1   \n",
       "\n",
       "     Tx_layer_space_y  wire_diameter  strand_number  Tx_current  \\\n",
       "717               1.4           0.08           27.0         3.0   \n",
       "61                0.9           0.07           29.0         6.0   \n",
       "849               2.3           0.06           99.0         6.0   \n",
       "352               0.5           0.06           59.0         6.0   \n",
       "116               0.2           0.05           15.0         8.0   \n",
       "830               1.5           0.07           55.0         6.0   \n",
       "809               0.6           0.06           67.0         6.0   \n",
       "804               1.0           0.06           85.0        10.0   \n",
       "858               1.3           0.05           39.0         5.0   \n",
       "355               1.1           0.05           37.0         7.0   \n",
       "697               1.3           0.05           15.0         7.0   \n",
       "847               2.4           0.06           95.0         8.0   \n",
       "637               0.6           0.05           83.0        10.0   \n",
       "636               0.5           0.05           51.0         2.0   \n",
       "692               1.6           0.06           59.0        10.0   \n",
       "414               1.6           0.07           29.0         7.0   \n",
       "221               0.9           0.06           19.0         4.0   \n",
       "316               0.9           0.06           57.0         4.0   \n",
       "102               3.3           0.05           45.0         3.0   \n",
       "310               0.7           0.06           65.0         4.0   \n",
       "49                0.8           0.05           47.0         6.0   \n",
       "695               0.9           0.07           31.0        10.0   \n",
       "298               1.3           0.05           11.0         7.0   \n",
       "700               3.6           0.08           31.0         2.0   \n",
       "508               0.9           0.06           47.0         8.0   \n",
       "751               3.9           0.05           37.0        10.0   \n",
       "527               0.9           0.07           29.0         6.0   \n",
       "192               0.9           0.06           57.0         2.0   \n",
       "532               1.8           0.05           25.0         3.0   \n",
       "416               1.1           0.05           91.0         5.0   \n",
       "104               1.7           0.05           79.0         7.0   \n",
       "181               4.5           0.06            9.0         4.0   \n",
       "868               1.3           0.06           15.0         7.0   \n",
       "68                3.8           0.08           25.0         5.0   \n",
       "451               1.3           0.06           27.0         9.0   \n",
       "271               1.3           0.08           71.0         8.0   \n",
       "38                2.6           0.08           23.0         2.0   \n",
       "896               2.1           0.05           43.0         5.0   \n",
       "230               0.5           0.06           59.0         6.0   \n",
       "666               1.8           0.06            7.0         8.0   \n",
       "322               2.7           0.05           97.0         4.0   \n",
       "183               1.1           0.07           63.0         7.0   \n",
       "222               0.8           0.06           53.0         2.0   \n",
       "894               3.1           0.05           45.0         6.0   \n",
       "556               0.3           0.07           73.0         8.0   \n",
       "48                0.3           0.07           37.0         7.0   \n",
       "95                1.8           0.06            9.0         7.0   \n",
       "197               0.5           0.08           37.0         8.0   \n",
       "47                1.9           0.06           35.0         4.0   \n",
       "430               0.9           0.08           13.0        10.0   \n",
       "180               0.6           0.08           25.0         5.0   \n",
       "459               0.5           0.07           35.0         2.0   \n",
       "237               0.2           0.08            7.0         9.0   \n",
       "58                3.2           0.05           19.0         2.0   \n",
       "665               1.4           0.05           63.0         4.0   \n",
       "397               0.5           0.05           67.0         2.0   \n",
       "798               2.2           0.05           75.0         7.0   \n",
       "457               1.1           0.05           37.0         7.0   \n",
       "235               0.6           0.05           27.0         2.0   \n",
       "612               2.8           0.06           97.0         1.0   \n",
       "223               0.5           0.05           61.0         1.0   \n",
       "60                1.1           0.06           35.0        10.0   \n",
       "218               0.9           0.05           11.0         7.0   \n",
       "1                 0.4           0.05           89.0         2.0   \n",
       "383               0.4           0.05           85.0         7.0   \n",
       "314               4.2           0.05           73.0         6.0   \n",
       "579               0.6           0.08           13.0         3.0   \n",
       "365               1.0           0.08           23.0         3.0   \n",
       "616               4.5           0.07           43.0         9.0   \n",
       "683               0.4           0.07           87.0         8.0   \n",
       "250               0.3           0.05           37.0         2.0   \n",
       "385               0.7           0.05           65.0         8.0   \n",
       "154               0.2           0.05           57.0         4.0   \n",
       "744               1.4           0.07           23.0         4.0   \n",
       "589               3.3           0.06           17.0         9.0   \n",
       "421               0.2           0.05           11.0         8.0   \n",
       "188               0.2           0.07           45.0         2.0   \n",
       "677               0.6           0.07           65.0         4.0   \n",
       "262               3.7           0.08           25.0         2.0   \n",
       "675               2.2           0.05           17.0         7.0   \n",
       "178               2.7           0.07           57.0         9.0   \n",
       "401               0.3           0.06           61.0         6.0   \n",
       "808               0.6           0.06           55.0         8.0   \n",
       "369               3.0           0.05           81.0         4.0   \n",
       "766               0.9           0.07           25.0         9.0   \n",
       "434               0.8           0.07           13.0         4.0   \n",
       "27                4.6           0.05           81.0         2.0   \n",
       "206               0.9           0.05           59.0         4.0   \n",
       "603               0.9           0.06           19.0         4.0   \n",
       "209               0.7           0.06           63.0         5.0   \n",
       "507               0.9           0.06           57.0         4.0   \n",
       "309               0.3           0.05           47.0         4.0   \n",
       "291               0.5           0.05           13.0         5.0   \n",
       "396               0.8           0.07           21.0         2.0   \n",
       "546               1.1           0.08           19.0         9.0   \n",
       "354               0.6           0.08           69.0         4.0   \n",
       "703               0.3           0.05           21.0         6.0   \n",
       "285               2.0           0.08           15.0         8.0   \n",
       "777               3.2           0.05           23.0         1.0   \n",
       "407               0.6           0.05           23.0         6.0   \n",
       "467               4.8           0.06           59.0         5.0   \n",
       "172               0.4           0.05           21.0         4.0   \n",
       "115               1.2           0.05           27.0         2.0   \n",
       "646               1.6           0.06           51.0         2.0   \n",
       "898               3.1           0.05           73.0         3.0   \n",
       "887               0.3           0.08           15.0         5.0   \n",
       "781               0.4           0.07           43.0         6.0   \n",
       "106               1.1           0.08           27.0         7.0   \n",
       "64                0.6           0.06           39.0         8.0   \n",
       "198               0.5           0.07           21.0         8.0   \n",
       "488               3.6           0.08           31.0         2.0   \n",
       "892               0.9           0.05           29.0         4.0   \n",
       "304               1.0           0.06           11.0         9.0   \n",
       "796               0.2           0.05           15.0         8.0   \n",
       "626               2.8           0.06           19.0         1.0   \n",
       "239               3.6           0.07           23.0         6.0   \n",
       "55                1.2           0.06           51.0         2.0   \n",
       "18                1.1           0.06           29.0         5.0   \n",
       "160               0.8           0.07           21.0         5.0   \n",
       "329               2.5           0.07           35.0         5.0   \n",
       "289               0.2           0.07           19.0         9.0   \n",
       "238               1.4           0.08           13.0         7.0   \n",
       "712               2.5           0.08           15.0         5.0   \n",
       "702               1.0           0.06           85.0        10.0   \n",
       "444               0.4           0.07            9.0         2.0   \n",
       "80                0.4           0.05           29.0         6.0   \n",
       "52                0.6           0.07           11.0         6.0   \n",
       "701               0.7           0.05           11.0        10.0   \n",
       "740               0.7           0.05           71.0         5.0   \n",
       "5                 4.1           0.08           31.0         6.0   \n",
       "226               0.7           0.05           27.0         4.0   \n",
       "152               0.2           0.05           39.0         8.0   \n",
       "900               0.5           0.06            7.0         6.0   \n",
       "642               2.7           0.05           15.0         8.0   \n",
       "872               2.1           0.05           43.0         5.0   \n",
       "718               1.0           0.05           47.0         4.0   \n",
       "85                0.3           0.05           71.0         3.0   \n",
       "518               0.9           0.06           19.0         4.0   \n",
       "652               1.1           0.06           35.0        10.0   \n",
       "190               1.6           0.06           19.0         8.0   \n",
       "168               0.8           0.06           75.0         3.0   \n",
       "680               1.1           0.06           21.0         1.0   \n",
       "821               1.8           0.06           51.0         4.0   \n",
       "679               0.2           0.08           33.0         9.0   \n",
       "261               1.6           0.06            9.0         5.0   \n",
       "572               0.9           0.06           15.0         7.0   \n",
       "167               0.3           0.07           25.0         7.0   \n",
       "632               4.9           0.07           19.0        10.0   \n",
       "189               0.7           0.05           81.0         3.0   \n",
       "324               0.2           0.06           75.0         3.0   \n",
       "\n",
       "     magnetizing_current_optimetric  magnetizing_copperloss_Rx1           0  \n",
       "717                          0.1177                     9.42777   11.150703  \n",
       "61                           0.2046                    14.01184   15.137108  \n",
       "849                          0.3871                    18.08360   20.563162  \n",
       "352                          0.1752                    19.06554   16.384743  \n",
       "116                          0.2859                    22.73135   31.510653  \n",
       "830                          0.1330                    22.73979   22.878154  \n",
       "809                          0.1649                    24.78600   23.311348  \n",
       "804                          0.3002                    25.03072   21.895882  \n",
       "858                          0.2547                    25.46158   28.438728  \n",
       "355                          0.1482                    26.00482   29.648731  \n",
       "697                          0.6746                    28.28771   26.280372  \n",
       "847                          0.7154                    31.68665   30.993986  \n",
       "637                          0.5356                    32.20206   32.434301  \n",
       "636                          0.9625                    33.16066   37.507830  \n",
       "692                          0.5333                    36.13046   47.540021  \n",
       "414                          0.5128                    37.87786   38.975894  \n",
       "221                          0.3086                    38.15481   35.671481  \n",
       "316                          0.4653                    38.73569   43.659318  \n",
       "102                          0.3581                    39.85247   44.896960  \n",
       "310                          0.3854                    41.98422   34.399520  \n",
       "49                           0.1621                    42.10525   35.236642  \n",
       "695                          0.5372                    44.57935   45.076126  \n",
       "298                          0.3019                    45.27591   53.797092  \n",
       "700                          0.1738                    49.23381   43.701506  \n",
       "508                          0.2973                    50.36384   43.230588  \n",
       "751                          1.0626                    52.54796   67.344199  \n",
       "527                          0.4091                    56.04738   55.561299  \n",
       "192                          0.4455                    56.70624   67.518948  \n",
       "532                          0.3337                    56.90404   47.683909  \n",
       "416                          0.6481                    60.50863   66.066810  \n",
       "104                          0.8274                    62.88313   74.015082  \n",
       "181                          0.3819                    64.93153   78.643261  \n",
       "868                          0.1591                    66.50368   67.736268  \n",
       "68                           0.7297                    67.17572   68.477684  \n",
       "451                          0.5209                    70.15578   77.225477  \n",
       "271                          0.1177                    70.59628   86.511421  \n",
       "38                           0.3105                    73.74491   74.839335  \n",
       "896                          0.2497                    74.12155   68.362665  \n",
       "230                          0.3504                    76.26218   82.003721  \n",
       "666                          0.5792                    77.98993   89.149306  \n",
       "322                          0.4428                    78.89038   90.883679  \n",
       "183                          0.6995                    79.26900  110.790958  \n",
       "222                          0.4643                    80.51822   82.797237  \n",
       "894                          0.4831                    86.92528   93.171476  \n",
       "556                          1.4853                    86.99712   94.734924  \n",
       "48                           0.3311                    90.82474   90.611772  \n",
       "95                           0.4950                    91.16133   92.868753  \n",
       "197                          0.5528                    91.90663   93.680441  \n",
       "47                           0.6771                    93.52649   87.978662  \n",
       "430                          0.2866                    94.87776   86.034622  \n",
       "180                          0.4412                    94.94159   95.074753  \n",
       "459                          0.4643                    95.06117   92.877635  \n",
       "237                          0.4057                    97.66239  104.506251  \n",
       "58                           0.7671                   100.61023   99.955828  \n",
       "665                          0.6158                   100.99092  102.712713  \n",
       "397                          0.5594                   103.05349  122.721252  \n",
       "798                          0.2813                   103.63490   90.838040  \n",
       "457                          0.2963                   104.01927   96.631578  \n",
       "235                          0.4185                   104.40253  130.469435  \n",
       "612                          0.6730                   105.36335  105.837386  \n",
       "223                          0.3378                   105.71788   92.385588  \n",
       "60                           0.5027                   106.41764  108.726684  \n",
       "218                          0.9688                   107.90509  100.332141  \n",
       "1                            0.4312                   110.61702  138.920095  \n",
       "383                          0.2439                   110.73877  104.522098  \n",
       "314                          0.5096                   111.97046  107.461235  \n",
       "579                          0.3598                   112.64699  107.975303  \n",
       "365                          0.5683                   112.66993  112.597605  \n",
       "616                          1.0379                   113.69324  129.027806  \n",
       "683                          0.2834                   113.72191  107.680912  \n",
       "250                          0.5950                   115.64036  120.296703  \n",
       "385                          0.5896                   116.04778  137.359643  \n",
       "154                          0.1516                   121.35658   55.894928  \n",
       "744                          0.2224                   121.42595  132.529505  \n",
       "589                          0.6517                   122.90848  115.797711  \n",
       "421                          0.6120                   123.30564  135.324723  \n",
       "188                          0.2287                   128.15191  167.816092  \n",
       "677                          0.3503                   128.85827  135.661454  \n",
       "262                          0.4862                   132.97389  164.396101  \n",
       "675                          1.6714                   135.87336  130.277915  \n",
       "178                          0.7102                   139.49941  126.287162  \n",
       "401                          0.3406                   140.04962  183.972712  \n",
       "808                          0.4859                   140.21587  188.176181  \n",
       "369                          1.1088                   141.08912  137.394072  \n",
       "766                          0.5120                   141.49729  135.615869  \n",
       "434                          0.4008                   145.03137  136.718768  \n",
       "27                           1.5506                   146.40723  140.778227  \n",
       "206                          0.3129                   148.38729  136.447035  \n",
       "603                          0.6173                   152.61926  186.048607  \n",
       "209                          1.0412                   153.77925  201.356787  \n",
       "507                          0.9306                   154.94275  183.159209  \n",
       "309                          1.1978                   158.87173  146.212914  \n",
       "291                          0.3873                   159.17913  163.602069  \n",
       "396                          1.2040                   165.71483  153.115543  \n",
       "546                          0.4561                   167.56651  140.017428  \n",
       "354                          0.2589                   170.16833  146.425673  \n",
       "703                          0.2452                   171.47202  181.960785  \n",
       "285                          0.4174                   173.35030  191.376364  \n",
       "777                          1.5394                   177.52857  175.792028  \n",
       "407                          0.4910                   177.77593  169.940998  \n",
       "467                          1.8695                   180.82880  218.266144  \n",
       "172                          0.6487                   182.28069  174.095063  \n",
       "115                          0.7564                   185.74673  161.364456  \n",
       "646                          2.1214                   186.14906  180.917821  \n",
       "898                          1.3570                   186.97470  230.027722  \n",
       "887                          0.6407                   187.33665  201.636512  \n",
       "781                          1.0197                   188.48307  175.491536  \n",
       "106                          0.9445                   192.66902  182.781395  \n",
       "64                           0.6106                   195.76612  192.237543  \n",
       "198                          0.3441                   196.08729  237.684452  \n",
       "488                          0.3475                   196.93523  198.135434  \n",
       "892                          0.4846                   200.33272  195.616015  \n",
       "304                          0.5841                   200.63012  216.870768  \n",
       "796                          0.8576                   204.58213  205.681571  \n",
       "626                          0.9990                   207.34720  218.162953  \n",
       "239                          2.1228                   213.61448  243.246390  \n",
       "55                           1.1168                   213.62910  199.097535  \n",
       "18                           0.8082                   213.74632  204.884796  \n",
       "160                          0.6667                   219.52807  266.805735  \n",
       "329                          0.6066                   223.31023  232.673048  \n",
       "289                          0.3957                   224.03710  222.505455  \n",
       "238                          1.8929                   225.02771  228.619017  \n",
       "712                          1.3931                   225.26580  269.912481  \n",
       "702                          0.9007                   225.27652  228.274477  \n",
       "444                          1.3176                   226.77930  285.277615  \n",
       "80                           0.7449                   227.53702  231.709368  \n",
       "52                           0.7183                   227.54875  257.301114  \n",
       "701                          0.4121                   227.75658  238.504072  \n",
       "740                          0.6615                   228.04836  233.613491  \n",
       "5                            1.3639                   228.69282  224.753245  \n",
       "226                          0.8588                   229.48111  265.381765  \n",
       "152                          1.1430                   230.38822  235.969000  \n",
       "900                          0.4460                   231.50437  256.560258  \n",
       "642                          1.0970                   232.81188  232.574853  \n",
       "872                          0.4993                   234.73619  281.071607  \n",
       "718                          0.9277                   235.01472  257.118620  \n",
       "85                           1.4606                   237.03396  265.930352  \n",
       "518                          0.7716                   238.46759  280.502491  \n",
       "652                          0.7540                   239.43970  240.107154  \n",
       "190                          0.1582                   243.30015  171.692168  \n",
       "168                          0.4760                   243.95378  234.724599  \n",
       "680                          0.5612                   250.38273  279.092837  \n",
       "821                          1.2806                   251.88231  232.634305  \n",
       "679                          0.8597                   252.39138  268.444230  \n",
       "261                          0.3822                   252.53912  330.101372  \n",
       "572                          1.4847                   253.69965  236.873783  \n",
       "167                          0.4286                   255.68962  221.904970  \n",
       "632                          0.7031                   256.16056  257.928607  \n",
       "189                          1.5932                   257.08511  365.982151  \n",
       "324                          0.7007                   258.12968  321.829359  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = model.predict(X_test)\n",
    "\n",
    "X_test_reset = X_test.reset_index(drop=True)\n",
    "Y_test_reset = Y_test.reset_index(drop=True)\n",
    "\n",
    "# 새로운 데이터프레임 temp2와 concat 시도\n",
    "\n",
    "result = pd.concat([X_test_reset,Y_test_reset, pd.DataFrame(temp)],axis=1)\n",
    "result_sorted = result.sort_values(by=param, ascending=True)\n",
    "result_sorted.head(150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deap_25v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
